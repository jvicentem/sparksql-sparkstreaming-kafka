{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SparkSQL assignment with Python\n",
    "## José Vicente Mellado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## No need to run these lines, everything has been configured in spark-env.sh\n",
    "\n",
    "#import findspark\n",
    "#findspark.init('/spark_dir')\n",
    "\n",
    "##Configuramos el sparksession\n",
    "#import pyspark\n",
    "#from pyspark.sql import SparkSession\n",
    "\n",
    "#spark = (SparkSession.builder\n",
    "#         .master('local[*]')\n",
    "#         .config('spark.driver.cores', 1)\n",
    "#         .appName('estudio_spark')\n",
    "#         .getOrCreate()\n",
    "#        )\n",
    "##obtenemos el sparkcontext a partir del sparksession\n",
    "#sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "st = StructType([\n",
    "        StructField('ID', LongType(), True),\n",
    "        StructField('PARENT-SYS-ID', StringType(), True),\n",
    "        StructField('Source', StringType(), True),\n",
    "        StructField('Mentions', StringType(), True),\n",
    "        StructField('Target', StringType(), True),\n",
    "        StructField('NAME Source', StringType(), True),\n",
    "        StructField('BODY', StringType(), True),\n",
    "        StructField('PUBDATE', TimestampType(), True),\n",
    "        StructField('URLs coma separated', StringType(), True),\n",
    "        StructField('Type TW-RT-MT', StringType(), True),\n",
    "        StructField('LINK', StringType(), True),\n",
    "        StructField('n1 Link', ByteType(), True),\n",
    "        StructField('n1 Picture', ByteType(), True),\n",
    "        StructField('PERSONAL-WEBSITE', StringType(), True),\n",
    "        StructField('COUNTRY', StringType(), True),\n",
    "        StructField('ALL-NICK-ACTIVITY-EVER', LongType(), True),\n",
    "        StructField('NICK-FOLLOWERS', LongType(), True),\n",
    "        StructField('FRIENDS-FOLLOWING-AUDIENCE', LongType(), True),\n",
    "        StructField('LOCATION', StringType(), True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "#https://spark.apache.org/docs/2.0.0-preview/api/python/pyspark.sql.html#pyspark.sql.DataFrameReader\n",
    "df = spark.read.csv('tweets.csv', \n",
    "                    header=True, \n",
    "                    sep='\\t',\n",
    "                    schema=st,\n",
    "                    timestampFormat='dd/MM/yyyy HH:mm',\n",
    "                    mode='PERMISSIVE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Contabilizar el número total de menciones a los pilotos Marc Márquez, Valentino Rossi y Dani Pedrosa.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('26_danipedrosa', 12341), ('marcmarquez93', 58027), ('valeyellow46', 61103)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.select('Mentions')\n",
    " .filter(df['Mentions'].like('%marcmarquez93%') | \n",
    "         df['Mentions'].like('%valeyellow46%') | \n",
    "         df['Mentions'].like('%26_danipedrosa%'))\n",
    " .rdd.flatMap(lambda mentions: \n",
    "              filter(lambda x: x == 'marcmarquez93' or x == 'valeyellow46' or x == '26_danipedrosa', \n",
    "                     list(set(mentions[0].split(',')))\n",
    "                    )\n",
    "             )\n",
    " .map(lambda user: (user, 1))\n",
    " .reduceByKey(lambda a, b: a + b)\n",
    " .collect()\n",
    ")\n",
    "\n",
    "# Alternative query\n",
    "#from pyspark.sql.functions import explode, split\n",
    "#\n",
    "#(df.select('ID', 'Mentions')\n",
    "# .filter(df['Mentions'].like('%marcmarquez93%') | \n",
    "#         df['Mentions'].like('%valeyellow46%') | \n",
    "#         df['Mentions'].like('%26_danipedrosa%'))\n",
    "# .withColumn('Mentions', explode((split('Mentions', ','))))\n",
    "# .distinct()\n",
    "# .filter('''Mentions = 'marcmarquez93' or \n",
    "#            Mentions = 'valeyellow46' or \n",
    "#            Mentions = '26_danipedrosa'\n",
    "#         ''')\n",
    "# .groupBy('Mentions')\n",
    "# .count() \n",
    "# .show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Contabilizar los 5 países que más tweets han publicado (considerando los tweets que contengan dicha información).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(COUNTRY='es', count=172577),\n",
       " Row(COUNTRY='us', count=12722),\n",
       " Row(COUNTRY='gb', count=12588),\n",
       " Row(COUNTRY='id', count=8725),\n",
       " Row(COUNTRY='it', count=1843)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.select('COUNTRY')\n",
    " .filter(df['COUNTRY'] != 'not public')\n",
    " .groupBy('COUNTRY')\n",
    " .count()\n",
    " .orderBy('count', ascending=False)\n",
    " .take(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Contabilizar los 3 hashtags más utilizados (que aparezcan el mayor número de veces) en el cuerpo de los tweets (campo \"body\").\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('#motogp', 51911), ('#qatar', 9974), ('#moto3', 5793)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.select('BODY')\n",
    " .filter(df['BODY'].like('%#%'))\n",
    " .rdd.flatMap(lambda mentions: \n",
    "              filter(lambda x: x.startswith('#'), \n",
    "                     list(set(mentions[0].split(' ')))\n",
    "                    )\n",
    "             )\n",
    " .map(lambda hashtag: (hashtag, 1))\n",
    " .reduceByKey(lambda a, b: a + b)\n",
    " .takeOrdered(3, key = lambda hashtag: -hashtag[1])\n",
    ")\n",
    "\n",
    "# Alternative query\n",
    "#(df.select('ID', 'BODY')\n",
    "# .filter(df['BODY'].like('%#%'))\n",
    "# .withColumn('BODY', explode((split('BODY', ' '))))\n",
    "# .distinct()\n",
    "# .filter(\"BODY like '#%'\")\n",
    "# .groupBy('BODY')\n",
    "# .count()\n",
    "# .orderBy('count', ascending=False)\n",
    "# .take(3)\n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Please run first the following lines: \n",
    "\n",
    "\n",
    "\n",
    "cd ./kafka_2.11-0.10.2.0/\n",
    "./bin/zookeeper-server-start.sh ./config/zookeeper.properties\n",
    "\n",
    "./bin/kafka-server-start.sh ./config/server.properties\n",
    "\n",
    "cd ./sparksql-sparkstreaming-kafka\n",
    "\n",
    "source activate conda_env_name\n",
    "\n",
    "python ./timestamp_kafka_producer.py Quatar_GP_2014 ./tweets.csv \n",
    "\n",
    "### Note: tweets.csv is sorted by date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following lines were provided by the teachers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.streaming.kafka import KafkaUtils\n",
    "from operator import add\n",
    "from operator import sub\n",
    "\n",
    "ssc = StreamingContext(sc, 5) # 5 seconds\n",
    "\n",
    "kafkaBrokerIPPort = \"127.0.0.1:9092\"\n",
    "\n",
    "import kafka\n",
    "\n",
    "class KafkaProducerWrapper(object):\n",
    "  producer = None\n",
    "  @staticmethod\n",
    "  def getProducer(brokerList):\n",
    "    if KafkaProducerWrapper.producer != None:\n",
    "      return KafkaProducerWrapper.producer\n",
    "    else:\n",
    "      KafkaProducerWrapper.producer = kafka.KafkaProducer(bootstrap_servers=brokerList, key_serializer=str.encode, value_serializer=str.encode)\n",
    "      return KafkaProducerWrapper.producer\n",
    " \n",
    "def sendMetrics(itr):\n",
    "  prod = KafkaProducerWrapper.getProducer([kafkaBrokerIPPort])\n",
    "  for m in itr:\n",
    "    prod.send(\"metrics\", key=m[0], value=m[0]+\",\"+str(m[1]))\n",
    "  prod.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ujson\n",
    "\n",
    "topic_name = 'Quatar_GP_2014'\n",
    "\n",
    "kafkaParams = {\"metadata.broker.list\": kafkaBrokerIPPort}\n",
    "stream = KafkaUtils.createDirectStream(ssc, [topic_name], kafkaParams)\n",
    "stream = stream.map(lambda o: ujson.loads(o[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Calcular el número total de menciones recibidas por cada cuenta de usuario durante el intervalo de 5 segundos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ssc.checkpoint(\"checkpoint\")\n",
    "\n",
    "counts = (stream.flatMap(lambda line: list(filter(lambda x: len(x) > 0, line['Mentions'].split(','))))\n",
    "                .map(lambda user: (user, 1)) \n",
    "                .reduceByKey(lambda a, b: a + b))\n",
    "\n",
    "counts.pprint()\n",
    "\n",
    "# In case we wanted to send the result to another Kafka queue\n",
    "#counts.foreachRDD(lambda rdd: rdd.foreachPartition(sendMetrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ssc.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Calcular la frecuencia total acumulada de apariciones de cada hashtag en el campo body, actualizando un ranking con los 5 hashtags con mayor frecuencia de aparición.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ssc.checkpoint(\"checkpoint\")\n",
    "\n",
    "top_5 = (stream.flatMap(lambda line: filter(lambda word: word.startswith('#'), list(set(line['BODY'].split(' ')))))\n",
    " .map(lambda hashtag: (hashtag, 1))\n",
    " .updateStateByKey(lambda currentVal, totalVal: sum(currentVal) + totalVal if totalVal != None else sum(currentVal))\n",
    " .transform(lambda rdd: rdd.sortBy(lambda x: x[1], False))\n",
    ")\n",
    "\n",
    "top_5.pprint(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2017-06-16 17:44:25\n",
      "-------------------------------------------\n",
      "('#motogp', [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "('#qatar', [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "('#unleashthebeast...', [1, 1, 1, 1, 1, 1, 1])\n",
      "('#moto2', [1, 1, 1, 1, 1, 1])\n",
      "('#valentinorossi', [1, 1, 1, 1])\n",
      "('#moto3', [1, 1, 1, 1])\n",
      "('#motogp:', [1, 1, 1, 1])\n",
      "('#gobrad!', [1, 1, 1, 1])\n",
      "('#losail', [1, 1, 1, 1])\n",
      "('#marquez', [1, 1, 1])\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2017-06-16 17:44:30\n",
      "-------------------------------------------\n",
      "('#motogp', [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "('#qatar', [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "('#unleashthebeast...', [1, 1, 1, 1, 1, 1, 1, 1])\n",
      "('#valentinorossi', [1, 1, 1, 1, 1, 1, 1])\n",
      "('#moto2', [1, 1, 1, 1, 1, 1])\n",
      "('#moto3', [1, 1, 1, 1])\n",
      "('#motogp:', [1, 1, 1, 1])\n",
      "('#megustanlasmotos', [1, 1, 1, 1])\n",
      "('#gobrad!', [1, 1, 1, 1])\n",
      "('#losail', [1, 1, 1, 1])\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2017-06-16 17:44:35\n",
      "-------------------------------------------\n",
      "('#motogp', [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "('#qatar', [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "('#unleashthebeast...', [1, 1, 1, 1, 1, 1, 1, 1])\n",
      "('#valentinorossi', [1, 1, 1, 1, 1, 1, 1])\n",
      "('#moto2', [1, 1, 1, 1, 1, 1])\n",
      "('#moto3', [1, 1, 1, 1])\n",
      "('#motogp:', [1, 1, 1, 1])\n",
      "('#megustanlasmotos', [1, 1, 1, 1])\n",
      "('#gobrad!', [1, 1, 1, 1])\n",
      "('#losail', [1, 1, 1, 1])\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2017-06-16 17:44:40\n",
      "-------------------------------------------\n",
      "('#motogp', [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "('#qatar', [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "('#unleashthebeast...', [1, 1, 1, 1, 1, 1, 1, 1])\n",
      "('#moto2', [1, 1, 1, 1, 1, 1, 1, 1])\n",
      "('#valentinorossi', [1, 1, 1, 1, 1, 1, 1])\n",
      "('#moto3', [1, 1, 1, 1, 1])\n",
      "('#motogp:', [1, 1, 1, 1, 1])\n",
      "('#megustanlasmotos', [1, 1, 1, 1])\n",
      "('#losail', [1, 1, 1, 1])\n",
      "('#gobrad!', [1, 1, 1, 1])\n",
      "...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ssc.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ssc.stop(False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [intro]",
   "language": "python",
   "name": "Python [intro]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
